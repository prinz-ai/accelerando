## A Chronicle of Events Leading to the Singularity[^1]

# 2025

***January 4***:  Sam Altman [writes](https://x.com/sama/status/1875603249472139576): "i always wanted to write a six-word story. here it is: ___ near the singularity; unclear which side."

***January 25***:  OpenAI [announces Project Stargate](https://openai.com/index/announcing-the-stargate-project/), which is intended to bring a massive amount of compute online over the next few years.  Other industry participants (xAI, Amazon, Microsoft, Meta, Google, *etc.*) quickly follow by significantly expanding their datacenter build-outs.

***February 24***:  Anthropic [releases Claude Code](https://www.anthropic.com/news/claude-3-7-sonnet).

***April 15***:  OpenAI updates its [Preparedness Framework](https://cdn.openai.com/pdf/18a02b5d-6b67-4cec-ab64-68cdfbddebcd/preparedness-framework-v2.pdf), isolating "AI self-improvement" as a category for the first time.  "High" risk associated with this capability as the equivalent of "giving every OpenAI researcher a highly performant mid-career research engineer assistant", relative to those researchers' 2024 baseline.

***April 16***:  OpenAI [releases Codex CLI](https://techcrunch.com/2025/04/16/openai-debuts-codex-cli-an-open-source-coding-tool-for-terminals/), initially designed to run locally from terminal software.  This release [is closely followed by a cloud-based version of Codex](https://openai.com/index/introducing-codex/) (on May 16).

***June 10***:  Sam Altman describes his vision of the future in an essay entitled [The Gentle Singularity](https://blog.samaltman.com/the-gentle-singularity) The essay begins with: "We are past the event horizon; the takeoff has started."

***September 15***:  OpenAI [releases a new version of Codex](https://openai.com/index/introducing-upgrades-to-codex/), based on GPT-5 (itself released just a few weeks prior).  Codex significantly grows in popularity following this release.

***September 29***:  On release of Sonnet 4.5, Anthropic [surveys 7 of its researchers](https://assets.anthropic.com/m/12f214efcc2f457a/original/Claude-Sonnet-4-5-System-Card.pdf) regarding the acceleration in their work from using Sonnet 4.5 in Claude Code.  The reported median productivity boost estimate is 20%-30%.

***October 29***: Sam Altman and Jakub Pachocki announce [during a livestream](https://www.youtube.com/watch?v=ngDCxlZcecw) that OpenAI is targeting an automated AI research intern for September 2026.  A fully automated AI researcher is to follow by March 2028.  Sam Altman later [posts](https://x.com/sama/status/1983584366547829073) that the "intern" will run on "hundreds of thousands of GPUs".

***November 19***:  OpenAI [asked GPT-5.1-Codex-Max](https://x.com/Miles_Brundage/status/1991238750802727373) to diagnose and explain 20 internal research and engineering bottlenecks that OpenAI has actually encountered in the past, each of which took ≈1 day for the OpenAI team to solve. The model scored 8% on this eval (named "OpenAI Q&A").

***November 24***:  Anthropic [releases Opus 4.5](https://www.anthropic.com/news/claude-opus-4-5), which immediately becomes the coding model of choice for most programmers.  In connection with this release, Anthropic [surveys 18 members of its technical staff](https://assets.anthropic.com/m/64823ba7485345a7/Claude-Opus-4-5-System-Card.pdf) to estimate the productivity boost they get from using Opus 4.5 in Claude Code.  50% of survey participants report productivity improvement of at least 100%; average reported productivity improvement is 220%.  Two researchers characterize the model as a "near-complete entry-level researcher replacement", albeit with "meaningful caveats".

***December 19***:  METR [announces](https://x.com/METR_Evals/status/2002203627377574113) that Opus 4.5 has a 50%-time horizon of approximately 4 hrs 49 mins, significantly higher than any other model released to date.

# 2026

***January 9***:  Anthropic's Jack Clark [reveals](https://post.substack.com/p/the-ai-revolution-is-here-will-the) that "the main thing" he worries about is "whether people succeed at 'building AI that builds AI' - fully closing the loop on AI R&D (sometimes called recursively self-improving AI)".

***January***:  A series of tweets from Anthropic and OpenAI researchers confirm that nearly all code at these labs is now written by Claude Code/Codex:  
* [Boris Cherny](https://x.com/bcherny/status/2015979257038831967) (Anthropic): "Pretty much 100% of (the Claude Code team's) code is written by Claude Code + Opus 4.5. For me personally it has been 100% for two+ months now, I don’t even make small edits by hand. I shipped 22 PRs yesterday and 27 the day before, each one 100% written by Claude."
* [Santiago Hernandez](https://x.com/santiaghini/status/2012447234806382665) (OpenAI): "recursive self-improvement is around the corner.  you can feel it in the corners of your terminal window"
* [roon](https://x.com/tszzl/status/2015253546372153347) (OpenAI): "programming always sucked... it's amazing how quickly I've moved on and don't miss even slightly... 100% (of coding is being done by Codex for me), I don't write code anymore"
* [Thibault Sottiaux](https://x.com/thsottiaux/status/2018258151603388639) (OpenAI): "Codex now pretty much builds itself, with the help and supervision of a great team.  The bottleneck has shifted to being how fast we can help and supervise the outcome."
* [Noam Brown](https://x.com/polynoamial/status/2018387805341380848) (OpenAI): "Codex is writing all my code these days."

***January 20***:  At the Davos conference, Dario Amodei [says that powerful AI is not that far off](https://x.com/deredleritt3r/status/2013613671704924640):

> The mechanism by which I imagined it would happen is that we would have models that are good at coding and AI research. And we would use that to create the new generation of models and speed it up, to create a loop that would increase the speed of model development. We are now at a point where I have engineers at Anthropic who say: 'I don't write any code anymore, I let the model write the code, I edit it, I do the things around it.' We might be 6-12 months away from a model that can do everything SWEs do end-to-end. And then the question is, how fast does that loop close? Not every part of that loop is something that can be sped up by AI. There's chips, manufacture of chips, training time for the model. There's a lot of uncertainty. It's easy to see how it could take a few years. It's very hard for me to see how it could take longer than that. But if I had to guess, I would guess that it goes faster than people imagine. And that key element of code, and increasingly research, going faster than people imagine - that's going to be the key driver.

***January 26***:  Dario Amodei, in "[The Adolescence of Technology](https://www.darioamodei.com/essay/the-adolescence-of-technology)", writes that AI "is now writing much of the code at Anthropic" and "already substantially accelerating the rate of our progress in building the next generation of AI systems".  He adds:  "This feedback loop is gathering steam month by month, and may be only 1-2 years away from a point where the current generation of AI autonomously builds the next."

[^1]: This chronicle starts in early 2025 with Anthropic's and OpenAI's releases of the first agentic coding models. The reader is well within his right to ask the author why this particular point was the one chosen as the threshold for crossing the event horizon. Would it not have been better to choose OpenAI's release of the first reasoning model (September 2024) as the threshold? Or perhaps the release of GPT-4? The release of GPT-3.5? Some even earlier ML milestone? The author agrees with this criticism and posits that, indeed, it is possible that mankind took its first firm step towards the singularity approximately 400,000 years ago when man first learned to control fire. Be that as it may, any chronicle has to start *somewhere*, and, in the author's view, having it start right before Sam Altman definitively wrote (in June 2025) that "we are past the event horizon; the takeoff has started" is as good a place as any. 